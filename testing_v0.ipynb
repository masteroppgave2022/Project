{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7f0e00797550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Import dependencies \"\"\"\n",
    "import os\n",
    "import rasterio\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from ML.ml_utils import ML_utils, CustomLoss\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # Second GPU on Aulus 4\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "import keras\n",
    "%matplotlib inline\n",
    "matplotlib.use('agg')\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Some useful methods \"\"\"\n",
    "def tile_xy(tile_name):\n",
    "    pos = tile_name.split('_')[1].split('.')[0]\n",
    "    x = int(pos.split('-')[0])\n",
    "    y = int(pos.split('-')[1])\n",
    "    return x,y\n",
    "\n",
    "def fetch_sorted_tiles(path_to_tiles):\n",
    "    tile_names = [tile for tile in os.listdir(path_to_tiles) if tile.endswith(\".tif\")]\n",
    "    tile_vals_y, tile_vals_x = [], []\n",
    "    for tile in tile_names:\n",
    "        x,y = tile_xy(tile)\n",
    "        tile_vals_x.append(x)\n",
    "        tile_vals_y.append(y)\n",
    "    max_val_y = max(tile_vals_y)\n",
    "    max_val_x = max(tile_vals_x)\n",
    "    tile_pixel_values = [*range(0,max(max_val_x,max_val_y) + 1,256)]\n",
    "    pixel_index_map = {}\n",
    "    for idx,pixel in enumerate(tile_pixel_values):\n",
    "        pixel_index_map[pixel] = idx\n",
    "    tiles = np.empty((int(max_val_x / 256)+1, int(max_val_y / 256)+1), dtype=object)\n",
    "    for tile in tile_names:\n",
    "        x,y = tile_xy(tile)\n",
    "        x = pixel_index_map[x]\n",
    "        y = pixel_index_map[y]\n",
    "        tiles[x][y] = tile      \n",
    "    return tiles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" User defined parameters \"\"\"\n",
    "dataset_name = 'data_flood_test'\n",
    "test_on_tiles = True\n",
    "masks = False\n",
    "path_to_model = '/localhome/studenter/mikaellv/Project/ML/models/DeepLabV3_Xception'\n",
    "\n",
    "model_name = os.path.split(path_to_model)[1]\n",
    "save_path_image_predictions = f'/localhome/studenter/mikaellv/Project/ML/predictions/predicted_images_{model_name}_{dataset_name}/'\n",
    "if test_on_tiles: save_path_image_predictions = save_path_image_predictions[:-1]+'_tiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load model \"\"\"\n",
    "ml = ML_utils(user='mikaellv')\n",
    "model = keras.models.load_model(path_to_model, custom_objects={'call':CustomLoss.call})\n",
    "\n",
    "\"\"\" Define test image paths \"\"\"\n",
    "path_to_images = \"data/datasets/\" + dataset_name + \"/test/images\"\n",
    "path_to_masks = \"data/datasets/\" + dataset_name + \"/test/masks\"\n",
    "\n",
    "\"\"\" Define classes \"\"\"\n",
    "classes = {\n",
    "    0: 'not_water',\n",
    "    1: 'water'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_on_tiles:\n",
    "    \"\"\" Test on 256x256 tiles \"\"\"\n",
    "    test_tile_paths = [path_to_images+'/'+f for f in os.listdir(path_to_images) if not f.endswith('.tif') and not f.startswith('.')]\n",
    "    images = []\n",
    "    predictions = []\n",
    "    if masks: segmentations = []\n",
    "    # Predict tiles\n",
    "    for tiles in test_tile_paths:\n",
    "        sorted_tile_paths = fetch_sorted_tiles(tiles)\n",
    "        preds = np.empty(sorted_tile_paths.shape, dtype=object)\n",
    "        for x in range(sorted_tile_paths.shape[0]):\n",
    "            for y in range(sorted_tile_paths.shape[1]):\n",
    "                img = ml.LoadImage(\n",
    "                    file=sorted_tile_paths[x][y], \n",
    "                    image_path=tiles,\n",
    "                    mask_path=None, \n",
    "                    fetch_mask=False)\n",
    "                img = np.expand_dims(img,axis=0)\n",
    "                preds[x,y] = model.predict(img).squeeze()\n",
    "        # Concatenate tiles to form full image\n",
    "        x_dim = []\n",
    "        for x in range(sorted_tile_paths.shape[0]):\n",
    "            y_dim = []\n",
    "            for y in range(sorted_tile_paths.shape[1]):\n",
    "                y_dim.append(preds[x,y])\n",
    "            x_dim.append(np.concatenate(y_dim,axis=0))\n",
    "        prediction = np.concatenate(x_dim, axis=1)\n",
    "        # Append predictions, images, masks to lists for visualization/performance metrics\n",
    "        img_name = f'{os.path.split(tiles)[1]}.tif'\n",
    "        img_shape = prediction.shape\n",
    "        if masks:\n",
    "            image, mask = ml.LoadImage(img_name,path_to_images,path_to_masks,fetch_mask=True)\n",
    "        if not masks: image = ml.LoadImage(img_name,path_to_images,path_to_masks, fetch_mask=False)\n",
    "        images.append(image[0:img_shape[0],0:img_shape[1],:])\n",
    "        predictions.append(prediction)\n",
    "        if masks:\n",
    "            mask = ml.bin_image(mask)\n",
    "            mask = ml.getSegmentationArr(mask,ml.N_CLASSES)\n",
    "            segmentations.append(mask[0:img_shape[0],0:img_shape[1],:])\n",
    "\n",
    "else:\n",
    "    \"\"\" Test on full-sized images \"\"\"\n",
    "    n_images = len([img for img in os.listdir(path_to_images) if img.endswith('.tif')])\n",
    "    test_data_generator = ml.DataGenerator(path_to_images,path_to_masks,train=False,masks=masks)\n",
    "    n_classes = len(classes)\n",
    "    predict_batch = 32\n",
    "    n_batch = n_images // 32\n",
    "    if not n_images % 32 == 0: n_batch += 1\n",
    "    images = []\n",
    "    predictions = []\n",
    "    if masks: segmentations = []\n",
    "    # Predict and append\n",
    "    for batch in range(0,n_batch):\n",
    "        if masks: imgs, masks = next(test_data_generator)\n",
    "        else: imgs = next(test_data_generator)\n",
    "        for i in range(0, len(imgs)):\n",
    "            img = np.expand_dims(imgs[i],axis=0)\n",
    "            images.append(imgs[i])\n",
    "            prediction = model.predict(img).squeeze()\n",
    "            predictions.append(prediction)\n",
    "            if masks: segmentations.append(masks[i][0:prediction.shape[0],0:prediction.shape[1],:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Set predictions to maximum value (single-band) \"\"\"\n",
    "for i in range(len(predictions)):\n",
    "    predictions[i] = np.argmax(predictions[i],axis=-1)\n",
    "    if masks: segmentations[i] = np.argmax(segmentations[i],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3801371/686485842.py:33: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axs = plt.subplots(1,2,figsize=(25,25))\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\"\"\" Save predicted images for visualization \"\"\"\n",
    "if not os.path.exists(save_path_image_predictions):\n",
    "    os.makedirs(save_path_image_predictions)\n",
    "result_path = os.path.split(save_path_image_predictions)[0] + '/results/'\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "count = 0\n",
    "if masks:\n",
    "    for img, pred, mask in zip(images,predictions,segmentations):\n",
    "        pred = np.rollaxis(pred,0,2)\n",
    "        pred = cv2.flip(pred,1)\n",
    "        pred = cv2.rotate(pred,cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        fig, axs = plt.subplots(1,3,figsize=(25,25))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        axs[0].imshow(img[:,:,0],cmap='PuBuGn_r')\n",
    "        axs[1].imshow(pred)\n",
    "        axs[2].imshow(mask)\n",
    "\n",
    "        axs[0].set_title(\"Original Image\")\n",
    "        axs[1].set_title(\"Prediction\")\n",
    "        axs[2].set_title(\"Ground Truth\")\n",
    "\n",
    "        plt.savefig(save_path_image_predictions + str(count) + '.png')\n",
    "        count += 1\n",
    "else:\n",
    "    for img, pred in zip(images,predictions):\n",
    "        pred = np.rollaxis(pred,0,2)\n",
    "        pred = cv2.flip(pred,1)\n",
    "        pred = cv2.rotate(pred,cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        fig, axs = plt.subplots(1,2,figsize=(25,25))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        axs[0].imshow(img[:,:,0],cmap='PuBuGn_r')\n",
    "        axs[1].imshow(pred)\n",
    "        \n",
    "        axs[0].set_title(\"Original Image\")\n",
    "        axs[1].set_title(\"Prediction\")\n",
    "\n",
    "        plt.savefig(save_path_image_predictions + str(count) + '.png')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIPPING] No ground truth for this test data.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Calculate performance \"\"\"\n",
    "if masks:\n",
    "    # Flatten arrays\n",
    "    print(\"[INFO] Flattening all numpy arrays... this may take a couple of minutes.\")\n",
    "    predictions = np.concatenate([np_array.ravel() for np_array in predictions])\n",
    "    segmentations = np.concatenate([np_array.ravel() for np_array in segmentations])\n",
    "\n",
    "    print(\"[INFO] Calculating precision/recall...\")\n",
    "    precision = metrics.precision_score(segmentations, predictions, average='weighted')\n",
    "    recall = metrics.recall_score(segmentations, predictions, average='weighted')\n",
    "    f1 = (2*precision*recall)/(recall+precision)\n",
    "    global_jaccard = metrics.jaccard_score(segmentations, predictions, average='weighted')\n",
    "    class_based_jaccard = metrics.jaccard_score(segmentations, predictions, average=None)\n",
    "    conf_mat = metrics.confusion_matrix(segmentations, predictions)\n",
    "    water_acc = (conf_mat[0,0])/(conf_mat[0,0]+conf_mat[0,1])\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(f\"Confusion matrix: \\n {conf_mat}\")\n",
    "    with open(result_path+\"performance_metrics.csv\", 'w') as f:\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"Test Data: {dataset_name}\\n\")\n",
    "        f.write(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score: {f1}\\nWater accuracy: {water_acc}\\n\")\n",
    "        f.write(f\"Weighted average Jaccard index: {global_jaccard}\\nJaccard by class: {class_based_jaccard}\\n\")\n",
    "        f.write(f\"Confusion matrix:\\n{conf_mat}\")\n",
    "else: print(\"[SKIPPING] No ground truth for this test data.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88863eb635f022b4d05b3776e0180ad34ecd491bf96b3346036d4de08ca08987"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
