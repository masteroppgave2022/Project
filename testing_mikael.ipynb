{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 18:15:27.036495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 18:15:27.064305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-27 18:15:27.064948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Import dependencies \"\"\"\n",
    "import os\n",
    "import rasterio\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from ML.ml_utils import ML_utils, CustomLoss\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # Second GPU on Aulus 4\n",
    "import keras\n",
    "matplotlib.use('agg')\n",
    "plt.ioff()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Some useful methods \"\"\"\n",
    "\n",
    "def tile_xy(tile_name):\n",
    "    pos = tile_name.split('_')[1].split('.')[0]\n",
    "    x = int(pos.split('-')[0])\n",
    "    y = int(pos.split('-')[1])\n",
    "    return x,y\n",
    "\n",
    "def fetch_sorted_tiles(path_to_tiles):\n",
    "    tile_names = [tile for tile in os.listdir(path_to_tiles) if tile.endswith(\".tif\")]\n",
    "    tile_vals_y, tile_vals_x = [], []\n",
    "    for tile in tile_names:\n",
    "        x,y = tile_xy(tile)\n",
    "        tile_vals_x.append(x)\n",
    "        tile_vals_y.append(y)\n",
    "    max_val_y = max(tile_vals_y)\n",
    "    max_val_x = max(tile_vals_x)\n",
    "    tile_pixel_values = [*range(0,max(max_val_x,max_val_y) + 1,256)]\n",
    "    pixel_index_map = {}\n",
    "    for idx,pixel in enumerate(tile_pixel_values):\n",
    "        pixel_index_map[pixel] = idx\n",
    "    tiles = np.empty((int(max_val_x / 256)+1, int(max_val_y / 256)+1), dtype=object)\n",
    "    for tile in tile_names:\n",
    "        x,y = tile_xy(tile)\n",
    "        x = pixel_index_map[x]\n",
    "        y = pixel_index_map[y]\n",
    "        tiles[x][y] = tile      \n",
    "    return tiles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" User defined parameters \"\"\"\n",
    "dataset_name = 'data_medium'\n",
    "test_on_tiles = True\n",
    "masks = False\n",
    "path_to_model = '/localhome/studenter/mikaellv/Project/ML/models/DeepLabV3'\n",
    "\n",
    "model_name = os.path.split(path_to_model)[1]\n",
    "save_path_image_predictions = f'/localhome/studenter/mikaellv/Project/ML/predictions/predicted_images_{model_name}_{dataset_name}/'\n",
    "if test_on_tiles: save_path_image_predictions = save_path_image_predictions[:-1]+'_tiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 16:13:59.037916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 16:13:59.043924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 16:13:59.044616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 16:13:59.045639: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-28 16:13:59.046932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 16:13:59.047556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 16:13:59.048143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 16:13:59.533184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 16:13:59.533820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 16:13:59.534412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-28 16:13:59.534999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9334 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:32:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load model \"\"\"\n",
    "ml = ML_utils(user='mikaellv')\n",
    "model = keras.models.load_model(path_to_model, custom_objects={'call':CustomLoss.call})\n",
    "\n",
    "\"\"\" Define test image paths \"\"\"\n",
    "path_to_images = \"data/datasets/\" + dataset_name + \"/test/images\"\n",
    "path_to_masks = \"data/datasets/\" + dataset_name + \"/test/masks\"\n",
    "\n",
    "\"\"\" Define classes \"\"\"\n",
    "classes = {\n",
    "    0: 'not_water',\n",
    "    1: 'water'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 16:14:16.005192: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n",
      "2022-04-28 16:14:16.343255: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1184, 1184, 3)\n"
     ]
    }
   ],
   "source": [
    "if test_on_tiles:\n",
    "    \"\"\" Test on 256x256 tiles \"\"\"\n",
    "    test_tile_paths = [path_to_images+'/'+f for f in os.listdir(path_to_images) if not f.endswith('.tif') and not f.startswith('.')]\n",
    "    images = []\n",
    "    predictions = []\n",
    "    if masks: segmentations = []\n",
    "    # Predict tiles\n",
    "    for tiles in test_tile_paths:\n",
    "        sorted_tile_paths = fetch_sorted_tiles(tiles)\n",
    "        preds = np.empty(sorted_tile_paths.shape, dtype=object)\n",
    "        for x in range(sorted_tile_paths.shape[0]):\n",
    "            for y in range(sorted_tile_paths.shape[1]):\n",
    "                img = ml.LoadImage(\n",
    "                    file=sorted_tile_paths[x][y], \n",
    "                    image_path=test_tile_paths,\n",
    "                    mask_path=None, \n",
    "                    fetch_mask=False)\n",
    "                img = np.expand_dims(img,axis=0)\n",
    "                preds[x,y] = model.predict(img).squeeze()\n",
    "        # Concatenate tiles to form full image\n",
    "        x_dim = []\n",
    "        for x in range(sorted_tile_paths.shape[0]):\n",
    "            y_dim = []\n",
    "            for y in range(sorted_tile_paths.shape[1]):\n",
    "                y_dim.append(preds[x,y])\n",
    "            x_dim.append(np.concatenate(y_dim,axis=0))\n",
    "        prediction = np.concatenate(x_dim, axis=1)\n",
    "        # Append predictions, images, masks to lists for visualization/performance metrics\n",
    "        img_name = f'{os.path.split(tiles)[1]}.tif'\n",
    "        image, mask = ml.LoadImage(img_name,path_to_images,path_to_masks,fetch_mask=True)\n",
    "        images.append(image)\n",
    "        predictions.append(prediction)\n",
    "        if masks: segmentations.append(mask)\n",
    "\n",
    "else:\n",
    "    \"\"\" Test full-sized images \"\"\"\n",
    "    n_images = len([img for img in os.listdir(path_to_images) if img.endswith('.tif')])\n",
    "    test_data_generator = ml.DataGenerator(path_to_images,path_to_masks,train=False,masks=masks)\n",
    "    n_classes = len(classes)\n",
    "    predict_batch = 32\n",
    "    n_batch = n_images // 32\n",
    "    if not n_images % 32 == 0: n_batch += 1\n",
    "    images = []\n",
    "    predictions = []\n",
    "    if masks: segmentations = []\n",
    "    # Predict and append\n",
    "    for batch in range(0,n_batch):\n",
    "        if masks: imgs, masks = next(test_data_generator)\n",
    "        else: imgs = next(test_data_generator)\n",
    "        for i in range(0, len(imgs)):\n",
    "            img = np.expand_dims(imgs[i],axis=0)\n",
    "            images.append(imgs[i])\n",
    "            predictions.append(model.predict(img))\n",
    "            if masks: segmentations.append(masks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Set predictions to maximum value (single-band) \"\"\"\n",
    "for i in range(len(predictions)):\n",
    "    predictions[i] = np.argmax(predictions[i],axis=-1)\n",
    "    if masks: segmentations[i] = np.argmax(segmentations[i],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\"\"\" Save predicted images for visualization \"\"\"\n",
    "if not os.path.exists(save_path_image_predictions):\n",
    "    os.makedirs(save_path_image_predictions)\n",
    "result_path = os.path.split(save_path_image_predictions)[0] + '/results/'\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "count = 0\n",
    "if masks:\n",
    "    for img, pred, mask in zip(images,predictions,segmentations):\n",
    "        pred = np.rollaxis(pred,0,3)\n",
    "        fig, axs = plt.subplots(1,3,figsize=(25,25))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        axs[0].imshow(img[:,:,0],cmap='PuBuGn_r')\n",
    "        axs[1].imshow(pred)\n",
    "        axs[2].imshow(mask)\n",
    "\n",
    "        axs[0].set_title(\"Original Image\")\n",
    "        axs[1].set_title(\"Prediction\")\n",
    "        axs[2].set_title(\"Ground Truth\")\n",
    "\n",
    "        plt.savefig(save_path_image_predictions + str(count) + '.png')\n",
    "        count += 1\n",
    "else:\n",
    "    for img, pred in zip(images,predictions):\n",
    "        pred = np.rollaxis(pred,0,2)\n",
    "        pred = cv2.flip(pred,1)\n",
    "        pred = cv2.rotate(pred,cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        fig, axs = plt.subplots(1,2,figsize=(25,25))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        axs[0].imshow(img[:,:,0],cmap='PuBuGn_r')\n",
    "        axs[1].imshow(pred)\n",
    "        \n",
    "        axs[0].set_title(\"Original Image\")\n",
    "        axs[1].set_title(\"Prediction\")\n",
    "\n",
    "        plt.savefig(save_path_image_predictions + str(count) + '.png')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generating training loss/accuracy plots.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'empty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/localhome/studenter/mikaellv/Project/testing_mikael.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baulus4.ies.ntnu.no/localhome/studenter/mikaellv/Project/testing_mikael.ipynb#ch0000007vscode-remote?line=8'>9</a>\u001b[0m     \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mstartswith(model_name) \u001b[39mand\u001b[39;00m file \u001b[39m!=\u001b[39m first_file:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baulus4.ies.ntnu.no/localhome/studenter/mikaellv/Project/testing_mikael.ipynb#ch0000007vscode-remote?line=9'>10</a>\u001b[0m         df_2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mML/saved_dataframes/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mfile)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baulus4.ies.ntnu.no/localhome/studenter/mikaellv/Project/testing_mikael.ipynb#ch0000007vscode-remote?line=10'>11</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m df_1\u001b[39m.\u001b[39;49mempty \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m df_2\u001b[39m.\u001b[39mempty:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baulus4.ies.ntnu.no/localhome/studenter/mikaellv/Project/testing_mikael.ipynb#ch0000007vscode-remote?line=11'>12</a>\u001b[0m     df \u001b[39m=\u001b[39m df_1\u001b[39m.\u001b[39mmerge(df_2)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baulus4.ies.ntnu.no/localhome/studenter/mikaellv/Project/testing_mikael.ipynb#ch0000007vscode-remote?line=12'>13</a>\u001b[0m     fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m,figsize\u001b[39m=\u001b[39m(\u001b[39m25\u001b[39m,\u001b[39m25\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'empty'"
     ]
    }
   ],
   "source": [
    "\"\"\" Calculate performance \"\"\"\n",
    "if masks:\n",
    "    # Flatten arrays\n",
    "    print(\"[INFO] Flattening all numpy arrays... this may take a couple of minutes.\")\n",
    "    predictions = np.concatenate([np_array.ravel() for np_array in predictions])\n",
    "    segmentations = np.concatenate([np_array.ravel() for np_array in segmentations])\n",
    "\n",
    "    print(\"[INFO] Calculating precision/recall...\")\n",
    "    precision = metrics.precision_score(segmentations, predictions, average='weighted')\n",
    "    recall = metrics.recall_score(segmentations, predictions, average='weighted')\n",
    "    f1 = (2*precision*recall)/(recall+precision)\n",
    "    global_jaccard = metrics.jaccard_score(segmentations, predictions, average='weighted')\n",
    "    class_based_jaccard = metrics.jaccard_score(segmentations, predictions, average=None)\n",
    "    conf_mat = metrics.confusion_matrix(segmentations, predictions)\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(f\"Confusion matrix: \\n {conf_mat}\")\n",
    "    with open(result_path+\"performance_metrics.csv\", 'w') as f:\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"Test Data: {dataset_name}\\n\")\n",
    "        f.write(f\"Precision: {precision}\\t\\tRecall: {recall}\\t\\tF1-Score: {f1}\\n\")\n",
    "        f.write(f\"Weighted average Jaccard index: {global_jaccard}\\t\\tJaccard by class: {class_based_jaccard}\\n\")\n",
    "        f.write(f\"Confusion matrix:\\n{conf_mat}\")\n",
    "else: print(\"[SKIPPING] No ground truth for this test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" Remove this cell \"\"\"\n",
    "# import rasterio\n",
    "# import numpy as np\n",
    "# from skimage import exposure\n",
    "\n",
    "# image_path = '/localhome/studenter/mikaellv/Project/data/datasets/data_medium/test/images/1/tile_512-512.tif'\n",
    "# img_name = '1'\n",
    "\n",
    "\n",
    "# image = rasterio.open(image_path).read()\n",
    "# image = np.rollaxis(image,0,3)\n",
    "# bands = image.shape[-1]\n",
    "\n",
    "# rescaled_image = np.zeros(image.shape,dtype=\"float32\")\n",
    "# for b in range(bands):\n",
    "#     p2 = np.percentile(image[:,:,b],2)\n",
    "#     p98 = np.percentile(image[:,:,b],98)\n",
    "#     rescaled_band = exposure.rescale_intensity(image[:,:,b],in_range=(p2,p98),out_range=(0,1))\n",
    "#     rescaled_image[:,:,b] = rescaled_band\n",
    "# image = rescaled_image\n",
    "\n",
    "\n",
    "# H_32 = int(image.shape[0]/32)*32\n",
    "# W_32 = int(image.shape[1]/32)*32\n",
    "\n",
    "# image = image[0:H_32,0: W_32,:]\n",
    "\n",
    "# image = np.expand_dims(image,axis=0)\n",
    "\n",
    "# prediction = model.predict(image)\n",
    "\n",
    "# image = image.squeeze()\n",
    "# prediction = np.argmax(prediction,axis=-1)\n",
    "\n",
    "# prediction = np.rollaxis(prediction,0,3)\n",
    "# fig, axs = plt.subplots(1,2,figsize=(25,25))\n",
    "# plt.tight_layout()\n",
    "\n",
    "# axs[0].imshow(image[:,:,0],cmap='PuBuGn_r')\n",
    "# axs[1].imshow(prediction)\n",
    "\n",
    "# axs[0].set_title(\"Original Image\")\n",
    "# axs[1].set_title(\"Prediction\")\n",
    "\n",
    "# count = 0\n",
    "# plt.savefig(img_name+ '_' + str(count) + '.png')\n",
    "# count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Remove this cell \"\"\"\n",
    "import rasterio\n",
    "from skimage import exposure\n",
    "\n",
    "image_path = '/localhome/studenter/renatask/Project/data/datasets/data_flood_test/test/images/baklidammen_S1A_IW_GRDH_1SDV_20200628T164709.tif.tif'\n",
    "img_name = 'baklidammen_S1A_IW_GRDH_1SDV_20200628T164709'\n",
    "\n",
    "\n",
    "image = rasterio.open(image_path).read()\n",
    "image = np.rollaxis(image,0,3)\n",
    "bands = image.shape[-1]\n",
    "\n",
    "rescaled_image = np.zeros(image.shape,dtype=\"float32\")\n",
    "for b in range(bands):\n",
    "    p2 = np.percentile(image[:,:,b],2)\n",
    "    p98 = np.percentile(image[:,:,b],98)\n",
    "    rescaled_band = exposure.rescale_intensity(image[:,:,b],in_range=(p2,p98),out_range=(0,1))\n",
    "    rescaled_image[:,:,b] = rescaled_band\n",
    "image = rescaled_image\n",
    "\n",
    "\n",
    "H_32 = int(image.shape[0]/32)*32\n",
    "W_32 = int(image.shape[1]/32)*32\n",
    "\n",
    "image = image[0:H_32,0: W_32,:]\n",
    "\n",
    "image = np.expand_dims(image,axis=0)\n",
    "\n",
    "prediction = model.predict(image)\n",
    "\n",
    "image = image.squeeze()\n",
    "prediction = np.argmax(prediction,axis=-1)\n",
    "\n",
    "prediction = np.rollaxis(prediction,0,3)\n",
    "fig, axs = plt.subplots(1,2,figsize=(25,25))\n",
    "plt.tight_layout()\n",
    "\n",
    "axs[0].imshow(image[:,:,0],cmap='PuBuGn_r')\n",
    "axs[1].imshow(prediction)\n",
    "\n",
    "axs[0].set_title(\"Original Image\")\n",
    "axs[1].set_title(\"Prediction\")\n",
    "\n",
    "plt.savefig('/localhome/studenter/renatask/Project/ML/predicted_images/' + model_name + 'test/' +img_name+ '_' + str(count) + '.png')\n",
    "count += 1\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88863eb635f022b4d05b3776e0180ad34ecd491bf96b3346036d4de08ca08987"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
